{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/mnt/n/model/Qwen/Qwen2-VL-2B-Instruct\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd37728902834df9979944be9cfde180"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load the model in half-precision on the available device(s)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mQwen2VLForConditionalGeneration\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mMODEL_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m processor \u001B[38;5;241m=\u001B[39m AutoProcessor\u001B[38;5;241m.\u001B[39mfrom_pretrained(MODEL_PATH)\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/modeling_utils.py:4225\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   4215\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_orig \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   4216\u001B[0m         torch\u001B[38;5;241m.\u001B[39mset_default_dtype(dtype_orig)\n\u001B[1;32m   4218\u001B[0m     (\n\u001B[1;32m   4219\u001B[0m         model,\n\u001B[1;32m   4220\u001B[0m         missing_keys,\n\u001B[1;32m   4221\u001B[0m         unexpected_keys,\n\u001B[1;32m   4222\u001B[0m         mismatched_keys,\n\u001B[1;32m   4223\u001B[0m         offload_index,\n\u001B[1;32m   4224\u001B[0m         error_msgs,\n\u001B[0;32m-> 4225\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_pretrained_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloaded_state_dict_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# XXX: rename?\u001B[39;49;00m\n\u001B[1;32m   4229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresolved_archive_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4232\u001B[0m \u001B[43m        \u001B[49m\u001B[43msharded_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharded_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4233\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_fast_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_fast_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4234\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4236\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4237\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_state_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_state_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4238\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4239\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4240\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4241\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgguf_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgguf_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4243\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4245\u001B[0m \u001B[38;5;66;03m# make sure token embedding weights are still tied if needed\u001B[39;00m\n\u001B[1;32m   4246\u001B[0m model\u001B[38;5;241m.\u001B[39mtie_weights()\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/modeling_utils.py:4728\u001B[0m, in \u001B[0;36mPreTrainedModel._load_pretrained_model\u001B[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001B[0m\n\u001B[1;32m   4724\u001B[0m                 set_module_tensor_to_device(\n\u001B[1;32m   4725\u001B[0m                     model_to_load, key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;241m*\u001B[39mparam\u001B[38;5;241m.\u001B[39msize(), dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   4726\u001B[0m                 )\n\u001B[1;32m   4727\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4728\u001B[0m         new_error_msgs, offload_index, state_dict_index \u001B[38;5;241m=\u001B[39m \u001B[43m_load_state_dict_into_meta_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4729\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_to_load\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4730\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4731\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstart_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4732\u001B[0m \u001B[43m            \u001B[49m\u001B[43mexpected_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4733\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4734\u001B[0m \u001B[43m            \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4735\u001B[0m \u001B[43m            \u001B[49m\u001B[43moffload_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4736\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate_dict_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate_dict_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4737\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate_dict_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate_dict_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4738\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4739\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4740\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_safetensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4741\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4742\u001B[0m \u001B[43m            \u001B[49m\u001B[43munexpected_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munexpected_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4743\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4744\u001B[0m         error_msgs \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m new_error_msgs\n\u001B[1;32m   4745\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   4746\u001B[0m     \u001B[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/modeling_utils.py:993\u001B[0m, in \u001B[0;36m_load_state_dict_into_meta_model\u001B[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001B[0m\n\u001B[1;32m    990\u001B[0m         param_device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_local_dist_rank_0() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeta\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    992\u001B[0m     \u001B[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001B[39;00m\n\u001B[0;32m--> 993\u001B[0m     \u001B[43mset_module_tensor_to_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mset_module_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    994\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    995\u001B[0m     hf_quantizer\u001B[38;5;241m.\u001B[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/accelerate/utils/modeling.py:329\u001B[0m, in \u001B[0;36mset_module_tensor_to_device\u001B[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001B[0m\n\u001B[1;32m    327\u001B[0m             module\u001B[38;5;241m.\u001B[39m_parameters[tensor_name] \u001B[38;5;241m=\u001B[39m param_cls(new_value, requires_grad\u001B[38;5;241m=\u001B[39mold_value\u001B[38;5;241m.\u001B[39mrequires_grad)\n\u001B[1;32m    328\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 329\u001B[0m     new_value \u001B[38;5;241m=\u001B[39m \u001B[43mvalue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    331\u001B[0m     new_value \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(value, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Load the model in half-precision on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_PATH, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Image\n",
    "url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Preprocess the inputs\n",
    "text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "# Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "output_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")\n",
    "print(output_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### multi-image\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
