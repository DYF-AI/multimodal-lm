{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Could not locate the modeling_GOT.py inside /mnt/n/model/ocr-pretrain-model/GOT-OCR2_0.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "/mnt/n/model/ocr-pretrain-model/GOT-OCR2_0 does not appear to have a file named modeling_GOT.py. Checkout 'https://huggingface.co//mnt/n/model/ocr-pretrain-model/GOT-OCR2_0/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m model_path \u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/n/model/ocr-pretrain-model/GOT-OCR2_0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_path, trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39meval()\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/modelscope/utils/hf_util.py:113\u001B[0m, in \u001B[0;36mget_wrapped_class.<locals>.ClassWrapper.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    111\u001B[0m     model_dir \u001B[38;5;241m=\u001B[39m pretrained_model_name_or_path\n\u001B[0;32m--> 113\u001B[0m module_obj \u001B[38;5;241m=\u001B[39m \u001B[43mmodule_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    114\u001B[0m \u001B[43m                                          \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m module_class\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAutoModel\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    117\u001B[0m     module_obj\u001B[38;5;241m.\u001B[39mmodel_dir \u001B[38;5;241m=\u001B[39m model_dir\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:441\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kwargs_copy\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch_dtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    439\u001B[0m         _ \u001B[38;5;241m=\u001B[39m kwargs_copy\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch_dtype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 441\u001B[0m     config, kwargs \u001B[38;5;241m=\u001B[39m \u001B[43mAutoConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    442\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_unused_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    446\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs_copy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39mauto_map:\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m trust_remote_code:\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:911\u001B[0m, in \u001B[0;36mAutoConfig.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    909\u001B[0m class_ref \u001B[38;5;241m=\u001B[39m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    910\u001B[0m module_file, class_name \u001B[38;5;241m=\u001B[39m class_ref\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 911\u001B[0m config_class \u001B[38;5;241m=\u001B[39m \u001B[43mget_class_from_dynamic_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    912\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    913\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    914\u001B[0m config_class\u001B[38;5;241m.\u001B[39mregister_for_auto_class()\n\u001B[1;32m    915\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m config_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/dynamic_module_utils.py:388\u001B[0m, in \u001B[0;36mget_class_from_dynamic_module\u001B[0;34m(pretrained_model_name_or_path, module_file, class_name, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001B[0m\n\u001B[1;32m    326\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    327\u001B[0m \u001B[38;5;124;03mExtracts a class from a module file, present in the local folder or repository of a model.\u001B[39;00m\n\u001B[1;32m    328\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;124;03mcls = get_class_from_dynamic_module(\"sgugger/my-bert-model\", \"modeling.py\", \"MyBertModel\")\u001B[39;00m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;124;03m```\"\"\"\u001B[39;00m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;66;03m# And lastly we get the class inside our newly created module\u001B[39;00m\n\u001B[0;32m--> 388\u001B[0m final_module \u001B[38;5;241m=\u001B[39m \u001B[43mget_cached_module_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m get_class_in_module(class_name, final_module\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/dynamic_module_utils.py:252\u001B[0m, in \u001B[0;36mget_cached_module_file\u001B[0;34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001B[0m\n\u001B[1;32m    248\u001B[0m     submodule \u001B[38;5;241m=\u001B[39m pretrained_model_name_or_path\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msep)\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 252\u001B[0m     resolved_module_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodule_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n\u001B[1;32m    265\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not locate the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m inside \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/utils/hub.py:380\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(resolved_file):\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _raise_exceptions_for_missing_entries:\n\u001B[0;32m--> 380\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Checkout \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    382\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available files.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m         )\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: /mnt/n/model/ocr-pretrain-model/GOT-OCR2_0 does not appear to have a file named modeling_GOT.py. Checkout 'https://huggingface.co//mnt/n/model/ocr-pretrain-model/GOT-OCR2_0/None' for available files."
     ]
    }
   ],
   "source": [
    "model_path =\"/mnt/n/model/ocr-pretrain-model/GOT-OCR2_0\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\n",
    "model = model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============rendering===============\n",
      "前 奏 00:00 由长笛主奏。\n",
      "主 歌 00:12 主唱用带有鼻音、滑音、真假声转换的山区民歌唱法唱出主歌。注意伴奏中对 位声部的出现。\n",
      "副 歌 00:51 加人和声声部。\n",
      "间 奏 01:31 由长笛奏出带有炫技的华彩乐段。\n",
      "第 二 段 01:13\n",
      "副 歌 01:51 加人铃鼓的伴奏。\n",
      "间 奏 02:10 由电吉他奏出炫技的华彩段落, 注意切分节奏。\n",
      "副 歌 02:30 加人铃鼓伴奏。\n",
      "副歌重复 02:50 只用掌声与打击乐伴奏。\n",
      "继续反复 03:09 伴奏乐器逐渐加人。\n",
      "尾 声 03:30 由电吉他奏出。\n",
      "\\section{摇滚乐}\n",
      "\\section{伤 心 旅 馆}\n",
      "[美] 埃尔维斯・普雷斯利 词曲\n",
      "\\section{听赏指南}\n",
      "摇滚乐是美国布鲁斯音乐与乡村音乐融合产生出的一种节奏感强烈的音乐。通常由一人或数 人演唱，每位乐手以能自弹、自唱、自编、自演为荣。\n",
      "关注歌曲中的节奏衬拍（小节中除重拍以外的弱拍）以及一拍中细分为二至三个的拍点，有 很强的摇晃感。\n",
      "关注低音的线条。\n",
      "你所了解的摇滚乐队演奏形式和特点:\n",
      "\\(1=C \\frac{4}{4}\\)\n",
      "(0.77) \\(\\left|\\left|\\frac{i}{i}\\right| \\frac{i}{i}\\right| \\quad \\mathrm{i} \\quad \\mathrm{I} \\quad \\mathrm{I} \\quad \\mathrm{I} \\quad \\mathrm{i} \\quad \\mathrm{I} \\quad \\mathrm{i} \\quad \\mathrm{J} \\quad \\mathrm{i} \\quad \\mathrm{i} \\quad \\mathrm{i} \\quad \\mathrm{I} \\quad \\mathrm{I}\\) 5 7 7.5\n",
      "Now since my ba - by left me, - I've found a new place to dwell, \\(\\left.\\left.\\frac{1}{i} \\frac{1}{i} \\frac{1}{i} \\frac{1}{i}\\right|_{i} \\frac{1}{i} \\frac{1}{i} \\frac{3}{3} \\frac{1}{3} \\frac{3}{3} \\frac{1}{3} \\frac{1}{i} \\frac{1}{i} \\frac{1}{} \\frac{5}{5} \\frac{7}{7} \\frac{1}{1} \\frac{1}{1} \\frac{1}{1} \\frac{1}{} \\frac{5}{5} \\frac{4}{4} \\frac{1}{4} \\frac{1}{4} \\frac{1}{1} \\frac{1}{1} \\frac{11}{1} \\frac{1}{1} \\frac{1}{1} \\mathrm{I} \\mathrm{I}\\)\n",
      "Down at the end of lone- ly st - reet, at Heart - break Ho - tel, I'm lone - ly\n"
     ]
    }
   ],
   "source": [
    "# input your test image\n",
    "# 拍照图片效果一般\n",
    "image_file = '/mnt/n/data/mllm-data/mllm-pretrain-data/test/crawler-data-保单材料/4034970a304e251f09afcb5da686c9177f3e533e.jpg'\n",
    "# 课本pdf图片, 有错别字但是能较好处理多列段落数据\n",
    "image_file = '/mnt/n/data/mllm-data/mllm-pretrain-data/test/image-book/（2003）美术鉴赏【公众号“电子课本大全”免费分享】_30.jpg'\n",
    "image_file = '/mnt/n/data/mllm-data/mllm-pretrain-data/test/image-book/（2019版）必修 音乐鉴赏（网络版）【公众号“电子课本大全”免费分享】_133.jpg'\n",
    "\n",
    "# plain texts OCR\n",
    "#res = model.chat(tokenizer, image_file, ocr_type='ocr')\n",
    "\n",
    "# format texts OCR:\n",
    "#res = model.chat(tokenizer, image_file, ocr_type='format')\n",
    "\n",
    "# fine-grained OCR:\n",
    "# res = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_box='')\n",
    "# res = model.chat(tokenizer, image_file, ocr_type='format', ocr_box='')\n",
    "# res = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_color='')\n",
    "# res = model.chat(tokenizer, image_file, ocr_type='format', ocr_color='')\n",
    "\n",
    "# multi-crop OCR:\n",
    "# res = model.chat_crop(tokenizer, image_file, ocr_type='ocr')\n",
    "# res = model.chat_crop(tokenizer, image_file, ocr_type='format')\n",
    "\n",
    "# render the formatted OCR results:\n",
    "res = model.chat(tokenizer, image_file, ocr_type='format', render=True, save_render_file = './demo.html')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
