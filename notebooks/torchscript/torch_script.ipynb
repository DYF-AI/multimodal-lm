{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### TorchScript\n",
    "TorchScript是PyTorch模型（nn.Module的子类）的中间表示，可以在高性能环境（例如C ++）中运行。\n",
    "\n",
    "在本教程中，我们将介绍PyTorch中的模型创作基础，包括：\n",
    "\n",
    "- 定义前向功能\n",
    "- 将模块组成模块的层次结构\n",
    "- 将PyTorch模块转换为TorchScript（我们的高性能部署运行时）的特定方法\n",
    "- 跟踪现有模块\n",
    "- 使用脚本直接编译模块\n",
    "- 如何组合这两种方法\n",
    "- 保存和加载TorchScript模块\n",
    "\n",
    "https://pytorch.panchuang.net/EigthSection/torchScript/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f402bcf3530>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "random.seed(42)\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 不包含控制流"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCellV1(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.5042, -0.4369, -0.4018, -0.3723],\n",
      "        [-0.0158, -0.0780,  0.0066, -0.4506],\n",
      "        [ 0.6633,  0.0949,  0.5463,  0.1301]], grad_fn=<TanhBackward0>), tensor([[ 0.5042, -0.4369, -0.4018, -0.3723],\n",
      "        [-0.0158, -0.0780,  0.0066, -0.4506],\n",
      "        [ 0.6633,  0.0949,  0.5463,  0.1301]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyCellV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCellV1, self).__init__()\n",
    "        self.linear = nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell_v1 = MyCellV1()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell_v1)\n",
    "print(my_cell_v1(x, h))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCellV2(\n",
      "  (dg): MyDecisionGate()\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.2552,  0.6342,  0.2439, -0.1345],\n",
      "        [ 0.0541,  0.7186,  0.1472,  0.1920],\n",
      "        [ 0.6442,  0.7811,  0.5944,  0.6411]], grad_fn=<TanhBackward0>), tensor([[ 0.2552,  0.6342,  0.2439, -0.1345],\n",
      "        [ 0.0541,  0.7186,  0.1472,  0.1920],\n",
      "        [ 0.6442,  0.7811,  0.5944,  0.6411]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "### 包含数据流的模型\n",
    "class MyDecisionGate(nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "\n",
    "class MyCellV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCellV2, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell_v2 = MyCellV2()\n",
    "print(my_cell_v2)\n",
    "print(my_cell_v2(x, h))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TorchScript-Tracing模块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCellV1(\n",
      "  original_name=MyCellV1\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[ 0.5042, -0.4369, -0.4018, -0.3723],\n         [-0.0158, -0.0780,  0.0066, -0.4506],\n         [ 0.6633,  0.0949,  0.5463,  0.1301]], grad_fn=<TanhBackward0>),\n tensor([[ 0.5042, -0.4369, -0.4018, -0.3723],\n         [-0.0158, -0.0780,  0.0066, -0.4506],\n         [ 0.6633,  0.0949,  0.5463,  0.1301]], grad_fn=<TanhBackward0>))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非控制流模型\n",
    "traced_cell_v1 = torch.jit.trace(my_cell_v1, (x, h))\n",
    "print(traced_cell_v1)\n",
    "print(traced_cell_v1.code)\n",
    "traced_cell_v1(x, h)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCellV2(\n",
      "  original_name=MyCellV2\n",
      "  (dg): MyDecisionGate(original_name=MyDecisionGate)\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  _1 = torch.tanh(_0)\n",
      "  return (_1, _1)\n",
      "\n",
      "(tensor([[ 0.2552,  0.6342,  0.2439, -0.1345],\n",
      "        [ 0.0541,  0.7186,  0.1472,  0.1920],\n",
      "        [ 0.6442,  0.7811,  0.5944,  0.6411]], grad_fn=<TanhBackward0>), tensor([[ 0.2552,  0.6342,  0.2439, -0.1345],\n",
      "        [ 0.0541,  0.7186,  0.1472,  0.1920],\n",
      "        [ 0.6442,  0.7811,  0.5944,  0.6411]], grad_fn=<TanhBackward0>))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14520/1488434821.py:4: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "# 对于存在控制流的代码，直接使用trace进行导出，导出的模型不对\n",
    "traced_cell_v2 = torch.jit.trace(my_cell_v2, (x, h))\n",
    "print(traced_cell_v2)\n",
    "print(traced_cell_v2.code)  # 没有if分支\n",
    "print(traced_cell_v2(x, h))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n",
      "graph(%self : __torch__.___torch_mangle_110.MyCellV3,\n",
      "      %x.1 : Tensor,\n",
      "      %h.1 : Tensor):\n",
      "  %9 : int = prim::Constant[value=1]()\n",
      "  %dg : __torch__.___torch_mangle_109.MyDecisionGateV2 = prim::GetAttr[name=\"dg\"](%self)\n",
      "  %linear : __torch__.torch.nn.modules.linear.___torch_mangle_7.Linear = prim::GetAttr[name=\"linear\"](%self)\n",
      "  %6 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x.1) # /tmp/ipykernel_14520/123614427.py:16:35\n",
      "  %7 : Tensor = prim::CallMethod[name=\"forward\"](%dg, %6) # /tmp/ipykernel_14520/123614427.py:16:27\n",
      "  %10 : Tensor = aten::add(%7, %h.1, %9) # /tmp/ipykernel_14520/123614427.py:16:27\n",
      "  %new_h.1 : Tensor = aten::tanh(%10) # /tmp/ipykernel_14520/123614427.py:16:16\n",
      "  %14 : (Tensor, Tensor) = prim::TupleConstruct(%new_h.1, %new_h.1)\n",
      "  return (%14)\n",
      "\n",
      "(tensor([[0.6765, 0.4108, 0.7917, 0.8712],\n",
      "        [0.2232, 0.1857, 0.6127, 0.5740],\n",
      "        [0.7781, 0.3506, 0.8757, 0.8357]], grad_fn=<TanhBackward0>), tensor([[0.6765, 0.4108, 0.7917, 0.8712],\n",
      "        [0.2232, 0.1857, 0.6127, 0.5740],\n",
      "        [0.7781, 0.3506, 0.8757, 0.8357]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGateV2(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCellV3(nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCellV3, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        #self.linear = torch.ones(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "# my_cell_v3 = MyCellV3(MyDecisionGate())\n",
    "# traced_cell_v3 = torch.jit.trace(my_cell_v3, (x, h))\n",
    "# print(traced_cell_v3.code)\n",
    "# print(traced_cell_v3.graph)\n",
    "print(\"+++\"*20)\n",
    "# 对于存在控制流的模型, 正确的做法\n",
    "scripted_gate = torch.jit.script(MyDecisionGateV2())\n",
    "my_cell_v3 = MyCellV3(scripted_gate)\n",
    "traced_cell_v3 = torch.jit.script(my_cell_v3)\n",
    "print(scripted_gate.code)\n",
    "print(traced_cell_v3.code)\n",
    "print(traced_cell_v3.graph)\n",
    "print(traced_cell_v3(x, h))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  output = (linear).forward(x, )\n",
      "  if bool(torch.gt(torch.sum(output), 0)):\n",
      "    output0 = output\n",
      "  else:\n",
      "    output0 = torch.neg(output)\n",
      "  output1 = torch.add_(output0, h)\n",
      "  new_h = torch.tanh(output1)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class MyCellV4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCellV4, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        #self.linear = torch.ones(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        output = self.linear(x)\n",
    "        if output.sum() > 0:\n",
    "            output = output\n",
    "        else:\n",
    "            output = -output\n",
    "        output += h\n",
    "        new_h = torch.tanh(output)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell_v4 = MyCellV4()\n",
    "traced_cell_v4 = torch.jit.script(my_cell_v4)\n",
    "print(traced_cell_v4.code)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  output = (linear).forward(x, )\n",
      "  if bool(torch.gt(torch.sum(output), 0)):\n",
      "    output0 = output\n",
      "  else:\n",
      "    output0 = torch.neg(output)\n",
      "  output1 = torch.add_(output0, h)\n",
      "  new_h = torch.tanh(output1)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "((tensor([[0.6765, 0.4108, 0.7917, 0.8712],\n          [0.2232, 0.1857, 0.6127, 0.5740],\n          [0.7781, 0.3506, 0.8757, 0.8357]],\n         grad_fn=<DifferentiableGraphBackward>),\n  tensor([[0.6765, 0.4108, 0.7917, 0.8712],\n          [0.2232, 0.1857, 0.6127, 0.5740],\n          [0.7781, 0.3506, 0.8757, 0.8357]],\n         grad_fn=<DifferentiableGraphBackward>)),\n (tensor([[0.5366, 0.4260, 0.5049, 0.3330],\n          [0.2708, 0.2315, 0.5867, 0.1803],\n          [0.7839, 0.4473, 0.8336, 0.5838]], grad_fn=<TanhBackward0>),\n  tensor([[0.5366, 0.4260, 0.5049, 0.3330],\n          [0.2708, 0.2315, 0.5867, 0.1803],\n          [0.7839, 0.4473, 0.8336, 0.5838]], grad_fn=<TanhBackward0>)),\n None,\n None)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_cell_v3(x,h), traced_cell_v4(x,h), print(traced_cell_v3.code), print(traced_cell_v4.code)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(input), 0)):\n",
      "    weight = self.weight\n",
      "    output = torch.mv(weight, input)\n",
      "  else:\n",
      "    weight0 = self.weight\n",
      "    output = torch.add(weight0, input)\n",
      "  return output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, N, M):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(N, M))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.sum() > 0:\n",
    "            output = self.weight.mv(input)\n",
    "        else:\n",
    "            output = self.weight + input\n",
    "        return output\n",
    "\n",
    "my_module = MyModule(10,20)\n",
    "sm = torch.jit.script(my_module)\n",
    "print(sm.code)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 混合脚本(Scripting)和跟踪(Tracing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  h = torch.zeros([3, 4])\n",
      "  y = torch.zeros([3, 4])\n",
      "  y0 = y\n",
      "  h0 = h\n",
      "  for i in range(torch.size(xs, 0)):\n",
      "    cell = self.cell\n",
      "    _0 = (cell).forward(torch.select(xs, 0, i), h0, )\n",
      "    y1, h1, = _0\n",
      "    y0, h0 = y1, h1\n",
      "  return (y0, h0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCellV3(scripted_gate), (x, h))\n",
    "\n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "\n",
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(rnn_loop.code)\n",
    "#print(rnn_loop.cell.dg.code)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WrapRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrapRNN, self).__init__()\n",
    "        self.loop = torch.jit.script(MyRNNLoop())\n",
    "\n",
    "    def forward(self, xs):\n",
    "        y, h = self.loop(xs)\n",
    "        return torch.relu(y)\n",
    "\n",
    "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
    "print(traced.code)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=WrapRNN\n",
      "  (loop): RecursiveScriptModule(\n",
      "    original_name=MyRNNLoop\n",
      "    (cell): RecursiveScriptModule(\n",
      "      original_name=MyCellV3\n",
      "      (dg): RecursiveScriptModule(original_name=MyDecisionGateV2)\n",
      "      (linear): RecursiveScriptModule(original_name=Linear)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traced.save('wrapped_rnn.zip')\n",
    "\n",
    "loaded = torch.jit.load('wrapped_rnn.zip')\n",
    "\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
